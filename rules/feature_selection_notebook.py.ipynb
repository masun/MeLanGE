{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91906b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython\n",
    "!pip install python-weka-wrapper3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c807ee9",
   "metadata": {
    "executionInfo": {
     "elapsed": 99861,
     "status": "ok",
     "timestamp": 1613579070933,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "mhMIceNIa5Zq"
   },
   "outputs": [],
   "source": [
    "import pygraphviz\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.classes import Random\n",
    "from weka.core.converters import Loader\n",
    "from weka.core.dataset import Instances\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "from weka.filters import Filter\n",
    "from weka.core.converters import Loader\n",
    "\n",
    "jvm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c768d8",
   "metadata": {
    "executionInfo": {
     "elapsed": 100213,
     "status": "ok",
     "timestamp": 1613579071301,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "bV1xOjroYonT"
   },
   "outputs": [],
   "source": [
    "from itertools import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de618631",
   "metadata": {
    "id": "BHtKWNhjrc_r"
   },
   "outputs": [],
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a605d81a",
   "metadata": {
    "executionInfo": {
     "elapsed": 121010,
     "status": "ok",
     "timestamp": 1613579092124,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "QEuR2gbK_fFa"
   },
   "outputs": [],
   "source": [
    "from weka.core.converters import Loader\n",
    "\n",
    "def LoadDataset(file, i):\n",
    "    print(\"Loading dataset\")\n",
    "    loader = Loader(classname=\"weka.core.converters.CSVLoader\")\n",
    "    data_file = file\n",
    "    data = loader.load_file(data_file)\n",
    "\n",
    "    print('Num instances: ', data.num_instances)\n",
    "    print('Num attributes: ', data.num_attributes)\n",
    "  \n",
    "    name_dataset = str(file).split(\".\")[0]\n",
    "    print(name_dataset)\n",
    "\n",
    "    #name dataset\n",
    "    df_evolution[\"Dataset\"].iloc[i]=name_dataset\n",
    "    df_evolution[\"Initial number instances\"].iloc[i]=data.num_instances\n",
    "    df_evolution[\"Initial number attributes\"].iloc[i]=data.num_attributes\n",
    "\n",
    "    return data, name_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e534c246",
   "metadata": {
    "id": "PrpfY6DVL8P6"
   },
   "outputs": [],
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5340b37",
   "metadata": {
    "executionInfo": {
     "elapsed": 121008,
     "status": "ok",
     "timestamp": 1613579092125,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "hU840xStZ5I9"
   },
   "outputs": [],
   "source": [
    "from weka.filters import Filter\n",
    "\n",
    "def FirstPreprocessing(data, i, att_class):\n",
    "    print(\"\")\n",
    "    print(\"Attribute to use as class: \" + str(att_class))\n",
    "    print(\"Preprocess number 1\")\n",
    "\n",
    "    df_evolution[\"Class\"].iloc[i]=att_class \n",
    "    \n",
    "    l = [\"genome\",\"index\", \"Family\", \"Bin_Id\", \"Unnamed: 0\", \"Genus\", \"orfs\",\"Genome_ID\", \"Genomes\", \"Genome\", \"Assembly\", \"Assembly accession\", \"Origin\"]\n",
    "\n",
    "    for x in l:\n",
    "    #Remove attribute by name\n",
    "        remove = Filter(classname=\"weka.filters.unsupervised.attribute.RemoveByName\", options=[\"-E\",str(x)])\n",
    "        remove.inputformat(data)     # let the filter know about the type of data to filter\n",
    "        data = remove.filter(data)  # filter the data\n",
    "\n",
    "    last_column = data.num_attributes\n",
    "    \n",
    "    print('Sample instances: ', data.num_instances)\n",
    "    print('Sample attributes: ', data.num_attributes)\n",
    "    \n",
    "    df_evolution[\"After pre-processing nr instances\"].iloc[i]=data.num_instances\n",
    "    df_evolution[\"After pre-processing nr attributes\"].iloc[i]=data.num_attributes\n",
    "  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b618c7e3",
   "metadata": {
    "id": "XFFYOV2DGpOR"
   },
   "outputs": [],
   "source": [
    "### Choose class: Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29b0a39",
   "metadata": {
    "executionInfo": {
     "elapsed": 121007,
     "status": "ok",
     "timestamp": 1613579092127,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "aswXpsmGhcSH"
   },
   "outputs": [],
   "source": [
    "def SelectClass(data):\n",
    "    print(\"\")\n",
    "    print(\"Defining last attribute as class\")\n",
    "    last_column = data.num_attributes\n",
    "    #We choose to classify on the nominal atrribute Genus. We first split our dataset to train and test, with a 80% to the train split.\n",
    "    #print('Classifying on: ', data.instance(last_column - 1)\n",
    "    data.class_index = last_column - 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09bd2457",
   "metadata": {
    "id": "z_oC3BAo1TPF"
   },
   "outputs": [],
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01542272",
   "metadata": {
    "executionInfo": {
     "elapsed": 121006,
     "status": "ok",
     "timestamp": 1613579092128,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "53iQU7wicaTm"
   },
   "outputs": [],
   "source": [
    "def LoaderSubsetEval(data, i, name_dataset, class_):\n",
    "    file = \"AfterFS/\" + name_dataset + \"_\" + class_ +\"_after_SubsetEval.csv\"\n",
    "    if file in os.listdir():\n",
    "        print(\"Loading output from SubsetEval to save time: \" + str(file))\n",
    "        from weka.core.converters import Loader\n",
    "        loader = Loader(classname=\"weka.core.converters.CSVLoader\")\n",
    "        data_file = file\n",
    "        data = loader.load_file(data_file)\n",
    "\n",
    "        print('Sample size: ', data.num_instances)\n",
    "        print('Sample size: ', data.num_attributes)\n",
    "\n",
    "        last_column = data.num_attributes\n",
    "        data.class_index = last_column - 1\n",
    "        print('Classifying on: ', data.attribute(last_column - 1))\n",
    "\n",
    "        df_evolution[\"After CfsSubsetEval nr instances\"].iloc[i]=data.num_instances\n",
    "        df_evolution[\"After CfsSubsetEval nr attributes\"].iloc[i]=data.num_attributes\n",
    "  \n",
    "    else: \n",
    "        data = AttributeSelectionSubsetEval(data, i, name_dataset, class_)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3c5c60",
   "metadata": {
    "executionInfo": {
     "elapsed": 121005,
     "status": "ok",
     "timestamp": 1613579092129,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "o3vT5PqqUA0m"
   },
   "outputs": [],
   "source": [
    "def AttributeSelectionSubsetEval(data, i, name_dataset, class_):\n",
    "    \"\"\"\n",
    "    evaluator: CfsSubsetEval\n",
    "    Evaluates the worth of a subset of attributes by considering the individual predictive ability of each feature along with the degree of redundancy between them.\n",
    "    Subsets of features that are highly correlated with the class while having low intercorrelation are preferred.\n",
    "\n",
    "    search: BestFirst\n",
    "    \"\"\"  \n",
    "    print(\"\")\n",
    "    print(\"Attribute Selection by CfsSubsetEval\")\n",
    "    from weka.filters import Filter\n",
    "    remove = Filter(classname=\"weka.filters.supervised.attribute.AttributeSelection\", options=[\"-E\",\"weka.attributeSelection.CfsSubsetEval -P 1 -E 1\", \n",
    "                                                                                             \"-S\", \"weka.attributeSelection.BestFirst -D 1 -N 5\"])\n",
    "    remove.inputformat(data)\n",
    "    filtered = remove.filter(data)\n",
    "    print('Sample size: ', filtered.num_instances)\n",
    "    print('Sample size: ', filtered.num_attributes)\n",
    "    data = filtered\n",
    "\n",
    "    output= \"AfterFS/\" + name_dataset + \"_\" + class_ +\"_after_SubsetEval.csv\"\n",
    "    # Save filtered dataset into csv file - backup\n",
    "    from weka.core.converters import Saver\n",
    "    saver = Saver(classname=\"weka.core.converters.CSVSaver\")\n",
    "    saver.save_file(data, output)\n",
    "\n",
    "    df_evolution[\"After CfsSubsetEval nr instances\"].iloc[i]=data.num_instances\n",
    "    df_evolution[\"After CfsSubsetEval nr attributes\"].iloc[i]=data.num_attributes\n",
    "\n",
    "    last_column = data.num_attributes\n",
    "    #We choose to classify on the nominal atrribute Genus. We first split our dataset to train and test, with a 80% to the train split.\n",
    "    print('Classifying on: ', data.attribute(last_column - 1))\n",
    "    data.class_index = last_column - 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8f0f96",
   "metadata": {
    "executionInfo": {
     "elapsed": 121003,
     "status": "ok",
     "timestamp": 1613579092129,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "sogLUOKZG_i1"
   },
   "outputs": [],
   "source": [
    "def GetOptimal(i):\n",
    "    print(\"Getting parameters from Feature_selection_correct.csv\")\n",
    "    optimal = {}\n",
    "    optimal[\"Optimal threshold\"] = int(right[\"Optimal threshold\"].iloc[i])\n",
    "    optimal[\"Optimal nr features\"] = int(right[\"Optimal nr features\"].iloc[i])\n",
    "    print(\"Threshold: \" + str(optimal[\"Optimal threshold\"]))\n",
    "    print(\"Nr features: \" + str(optimal[\"Optimal nr features\"]))\n",
    "    return optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021f66a7",
   "metadata": {
    "executionInfo": {
     "elapsed": 121203,
     "status": "ok",
     "timestamp": 1613579092331,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "EQJcgfD5V1pE"
   },
   "outputs": [],
   "source": [
    "def AttributeSelectionInfoGain(data, threshold):\n",
    "    \"\"\"\n",
    "    evaluator: InfoGainAttributeEval\n",
    "    Evaluates the worth of an attribute by measuring the information gain with respect to the class.\n",
    "    InfoGain(Class,Attribute) = H(Class) - H(Class | Attribute).\n",
    "  \n",
    "    search: Ranker\n",
    "    \"\"\"\n",
    "    print(\"Attribute Selection by InfoGain. Threshold: \" +str(threshold))\n",
    "    from weka.filters import Filter\n",
    "    remove = Filter(classname=\"weka.filters.supervised.attribute.AttributeSelection\",\\\n",
    "                         options=[\"-S\", \"weka.attributeSelection.Ranker -T {} -N -1\".format(str(threshold)), #T: threshold \n",
    "                                  \"-E\", \"weka.attributeSelection.InfoGainAttributeEval\"])\n",
    "    remove.inputformat(data)\n",
    "    filtered = remove.filter(data)\n",
    "    \n",
    "    print('Sample size: ', filtered.num_instances)\n",
    "    print('Sample size: ', filtered.num_attributes)\n",
    "    n_att = filtered.num_attributes\n",
    "  \n",
    "    return filtered, n_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64aa1937",
   "metadata": {
    "id": "j2peSaWDDlhw"
   },
   "outputs": [],
   "source": [
    "### Classifier - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a4b07f5",
   "metadata": {
    "executionInfo": {
     "elapsed": 121202,
     "status": "ok",
     "timestamp": 1613579092332,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "Vz1xzIQoxyBh"
   },
   "outputs": [],
   "source": [
    "def Classifier(data, nfeatures):\n",
    "    #set Train and Test data\n",
    "    from weka.filters import Filter\n",
    "    remove = Filter(classname=\"weka.filters.supervised.instance.Resample\",\\\n",
    "                         options=[\"-B\", \"0.0\", \"-S\", \"1\", \"-Z\", \"80\", \"-no-replacement\"])\n",
    "    remove.inputformat(data)\n",
    "    train = remove.filter(data)\n",
    "    print('Train size: ', train.num_instances)\n",
    "    print('Train size: ', train.num_attributes)\n",
    "    remove = Filter(classname=\"weka.filters.supervised.instance.Resample\",\\\n",
    "                         options=[\"-B\", \"0.0\", \"-S\", \"1\", \"-Z\", \"80\", \"-no-replacement\", \"-V\"])\n",
    "    remove.inputformat(data)\n",
    "    test = remove.filter(data)\n",
    "    print('Test size: ', test.num_instances)\n",
    "    print('Test size: ', test.num_attributes)\n",
    "    \n",
    "    from weka.classifiers import Classifier, Evaluation, PredictionOutput\n",
    "    #Train the classifier\n",
    "    cls = Classifier(classname=\"weka.classifiers.trees.RandomForest\", options=[\"-P\",\"100\",\"-attribute-importance\",\"-K\",str(nfeatures)])\n",
    "    cls.build_classifier(train)\n",
    "\n",
    "    # Evaluating the classifier\n",
    "    # cross-validation\n",
    "    evlCV = Evaluation(train)\n",
    "    try:\n",
    "        evlCV.crossvalidate_model(cls, train, 10, Random(1))#, output=pred_output)\n",
    "    except:\n",
    "        evlCV.crossvalidate_model(cls, train, 2, Random(1))#, output=pred_output)\n",
    "    print(evlCV.summary(title=\"cross-validation\"))\n",
    "    #print(pout.buffer_content())\n",
    "\n",
    "    # evaluate the built model on the test set\n",
    "    evlTest = Evaluation(test)\n",
    "    evlTest.test_model(cls, test)\n",
    "    print(evlTest.summary(title=\"test\"))\n",
    "\n",
    "    return evlTest, evlCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d6c322",
   "metadata": {
    "id": "QG44HezV1GER"
   },
   "outputs": [],
   "source": [
    "### Select better threshold and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb7ec0c",
   "metadata": {
    "executionInfo": {
     "elapsed": 121200,
     "status": "ok",
     "timestamp": 1613579092333,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "bwvYyjBQ6bta"
   },
   "outputs": [],
   "source": [
    "def SelectionOptimalParam(data, i, class_):\n",
    "    \"\"\"\n",
    "    -K <number of attributes> \\\n",
    "    # Number of attributes to randomly investigate. (default 0) \n",
    "    \"\"\"\n",
    "    print(\"\")\n",
    "    print(\"Selecting best parameters\")\n",
    "  \n",
    "    threshold_list = [0.0, 0.10, 0.20, 0.30, 0.40,0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.96, 0.97, 0.98, 0.99]\n",
    "    nr_features_list = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n",
    "    threshold_eval = {}\n",
    "    feature_eval = {}\n",
    "    feature_eval_backupf_measure = {}\n",
    "    d = {}\n",
    "    d2 = {}\n",
    "    d3_f = {}\n",
    "    optimal = {}\n",
    "\n",
    "    for t in threshold_list:\n",
    "        print(\"\")\n",
    "        print(\"Threshold: \" + str(t))\n",
    "        data_AS, n_att = AttributeSelectionInfoGain(data, t)\n",
    "        feature_eval = {}\n",
    "        d2[t] = []\n",
    "        d2[t].append(n_att)\n",
    "        d3_f[t] = []\n",
    "        d3_f[t].append(n_att)\n",
    "        \n",
    "    for f in nr_features_list:\n",
    "        print(\"Number of features: \" + str(f))\n",
    "        evl, evlCV = Classifier(data_AS, f)\n",
    "        last_column = data_AS.num_attributes\n",
    "        feature_eval[f] = evl.percent_correct \n",
    "        feature_eval_backupf_measure[f] = evlCV.weighted_f_measure\n",
    "        print(\"Accuracy: \" + str(evl.percent_correct))\n",
    "        print(\"Weighted recall: \" + str(evl.weighted_recall))\n",
    "        print(\"F-measure: \" + str(evlCV.weighted_f_measure))\n",
    "        d2[t].append(feature_eval[f]) #accuracy of test\n",
    "        d3_f[t].append(feature_eval_backupf_measure[f]) #f-measure of cross-validation\n",
    "    #best_feature_nr = str(max(feature_eval, key=feature_eval.get)) # accuracy as metric\n",
    "    best_feature_nr = str(max(feature_eval_backupf_measure, key=feature_eval_backupf_measure.get)) #f-masure as metric\n",
    "    d[t] = best_feature_nr\n",
    "    threshold_eval[t] = str(feature_eval[int(best_feature_nr)])\n",
    "    #print(\"Number features with better results for threshold \" + str(t) + \": \" + best_feature_nr +\" with \" + str(threshold_eval[t]) + \" F-measure.\")\n",
    "    #print(\"-----------------------\")\n",
    "\n",
    "    print(\"Conclusions: \")\n",
    "    \n",
    "    better_threshold = str(max(threshold_eval, key=threshold_eval.get))\n",
    "    optimal[\"Optimal threshold\"] = better_threshold\n",
    "    optimal[\"Optimal nr features\"] = d[float(better_threshold)]\n",
    "    \n",
    "    print(\"Threshold with better results: \" + better_threshold + \" with \" + str(threshold_eval[float(better_threshold)]) +\" F-measure \" + \"for \" + d[float(better_threshold)] + \" number of features.\")\n",
    "  \n",
    "    df_evolution[\"Optimal threshold\"].iloc[i]=better_threshold\n",
    "    df_evolution[\"Optimal nr features\"].iloc[i]=d[float(better_threshold)]\n",
    "\n",
    "    return d2, d3_f, optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa8feef0",
   "metadata": {
    "executionInfo": {
     "elapsed": 121199,
     "status": "ok",
     "timestamp": 1613579092334,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "5tzSQO1qpk_l"
   },
   "outputs": [],
   "source": [
    "def PlotOptimalParam(d2, att_class):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    df = pd.DataFrame.from_dict(d2, orient='index', columns=[\"Nr_attributes\",'1','3','5', '7', '9', '11', '13'])\n",
    "\n",
    "    df2 = df.drop(columns=[\"Nr_attributes\"])\n",
    "    df2= df2.T.max()\n",
    "\n",
    "    df3 = df[\"Nr_attributes\"]\n",
    "    d3 = df3.T\n",
    "\n",
    "    #https://matplotlib.org/gallery/api/two_scales.html\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    title=  \"Feature Selection - Evaluation on test dataset from \" + name_dataset+ \"_\" + att_class\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel(\"InfoGain Threshold\")\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(df2, color=color)\n",
    "    ax1.set_ylabel('Accuracy', color=color)\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.plot(df3, color=color)\n",
    "    ax2.set_ylabel(\"Number of attributes\", color=color)  # we already handled the x-label with ax1\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    fig.tight_layout() \n",
    "    output_file = name_dataset + \"_\" + att_class + \"_accuracy_best_metrics.png\"\n",
    "    #plt.savefig(output_file, bbox_inches = 'tight')  # osandragodinhosilva@gmail.comtherwise the right y-label is slightly clipped\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b925a3c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 121199,
     "status": "ok",
     "timestamp": 1613579092335,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "zK7iK7rfYaUu"
   },
   "outputs": [],
   "source": [
    "def PlotOptimalParamFMeasure(d3_f, att_class):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    df = pd.DataFrame.from_dict(d3_f, orient='index', columns=[\"Nr_attributes\",'1','3', '5', '7', '9', '11', '13'])\n",
    "  \n",
    "  #df.to_csv(\"COG_selector_function_output.csv\")\n",
    "  #df =pd.read_csv(\"COG_selector_function_output.csv\")\n",
    "  #df.set_index(\"Unnamed: 0\",inplace=True)\n",
    "\n",
    "    df2 = df.drop(columns=[\"Nr_attributes\"])\n",
    "    df2= df2.T.max()\n",
    "\n",
    "    df3 = df[\"Nr_attributes\"]\n",
    "    d3 = df3.T\n",
    "\n",
    "  #https://matplotlib.org/gallery/api/two_scales.html\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    title=  \"Feature Selection - Cross-validation on train dataset from \" + name_dataset + \"_\" + att_class\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel(\"InfoGain Threshold\")\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(df2, color=color)\n",
    "    ax1.set_ylabel('F-measure', color=color)\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.plot(df3, color=color)\n",
    "    ax2.set_ylabel(\"Number of attributes\", color=color)  # we already handled the x-label with ax1\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    fig.tight_layout() \n",
    "    output_file = name_dataset + \"_\" + att_class + \"_f_measure_best_metrics.png\"\n",
    "    #plt.savefig(output_file, bbox_inches = 'tight')  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3551ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 121197,
     "status": "ok",
     "timestamp": 1613579092335,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "2ayQqJ6n3BOx"
   },
   "outputs": [],
   "source": [
    "def ImplementFeatureSelection(data, optimal, i):\n",
    "    from weka.classifiers import Classifier, Evaluation, PredictionOutput\n",
    "    from weka.filters import Filter\n",
    "    print(\"\")\n",
    "    print(\"Implementing best parameters: Feature Selection\")\n",
    "  #CfsSubsetEval\n",
    "  # Implement Feature Selection\n",
    "    data, n_att = AttributeSelectionInfoGain(data, optimal['Optimal threshold'])\n",
    "\n",
    "  #set Train and Test data\n",
    "    remove = Filter(classname=\"weka.filters.supervised.instance.Resample\",\\\n",
    "                         options=[\"-B\", \"0.0\", \"-S\", \"1\", \"-Z\", \"80\", \"-no-replacement\"])\n",
    "    remove.inputformat(data)\n",
    "    train = remove.filter(data)\n",
    "    print('Train size: ', train.num_instances)\n",
    "    print('Train size: ', train.num_attributes)\n",
    "  \n",
    "    remove = Filter(classname=\"weka.filters.supervised.instance.Resample\",\\\n",
    "                         options=[\"-B\", \"0.0\", \"-S\", \"1\", \"-Z\", \"80\", \"-no-replacement\", \"-V\"])\n",
    "    remove.inputformat(data)\n",
    "    test = remove.filter(data)\n",
    "    print('Test size: ', test.num_instances)\n",
    "    print('Test size: ', test.num_attributes)\n",
    "\n",
    "  #Train the classifier\n",
    "    cls = Classifier(classname=\"weka.classifiers.trees.RandomForest\", options=[\"-P\",\"100\",\"-attribute-importance\",\"-K\",str(optimal[\"Optimal nr features\"])])\n",
    "    cls.build_classifier(train)\n",
    "    pred_output = PredictionOutput(classname=\"weka.classifiers.evaluation.output.prediction.PlainText\", options=[\"-distribution\"])# outputfile])\n",
    "\n",
    "  # Evaluating the classifier\n",
    "  # cross-validation\n",
    "    evlCV = Evaluation(train)\n",
    "    try:\n",
    "        evlCV.crossvalidate_model(cls, train, 10, Random(1), output=pred_output)\n",
    "    except:\n",
    "        evlCV.crossvalidate_model(cls, train, 2, Random(1), output=pred_output)\n",
    "    print(evlCV.summary(title=\"cross-validation\"))\n",
    "\n",
    "  # evaluate the built model on the test set\n",
    "    evlTest = Evaluation(test)\n",
    "    evlTest.test_model(cls, test)\n",
    "    print(evlTest.summary(title=\"test\"))\n",
    "\n",
    "  #Save in evolution dataframe\n",
    "    df_evolution[\"After InfoGainAttributeEval nr instances\"].iloc[i] = data.num_instances\n",
    "    df_evolution[\"After InfoGainAttributeEval nr attributes\"].iloc[i] = data.num_attributes\n",
    "\n",
    "    df_evolution[\"Training cross-validation (f-measure)\"].iloc[i] = evlCV.weighted_f_measure\n",
    "    df_evolution[\"Training cross-validation (accuracy)\"].iloc[i] =  evlCV.percent_correct\n",
    "\n",
    "    df_evolution[\"Evaluation (f-measure)\"].iloc[i] = evlTest.weighted_f_measure\n",
    "    df_evolution[\"Evaluation (accuracy)\"].iloc[i] = evlTest.percent_correct\n",
    "  \n",
    "  #Save attributes selected\n",
    "    l_att = []\n",
    "    for x in data.attributes():\n",
    "        a = str(x).split(\" \")[1]\n",
    "        l_att.append(a)\n",
    "\n",
    "    df_evolution[\"Selected attributes\"].iloc[i]=  l_att\n",
    "  #print(\"weightedPrecision: \" + str(evaluation.weighted_precision))\n",
    "  #print(\"weightedRecall: \" + str(evaluation.weighted_recall))\n",
    "  \n",
    "    return data, evlTest, cls, pred_output\n",
    "\n",
    "# pred_output - Predictions\n",
    "# cls # Classifier output (if attribute importance is on, also this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41c92c47",
   "metadata": {
    "id": "9TAJGax0ExUa"
   },
   "outputs": [],
   "source": [
    "### Save Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0316ee9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 121434,
     "status": "ok",
     "timestamp": 1613579092574,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "jEK2OCoGoJRY"
   },
   "outputs": [],
   "source": [
    "def SaveFinaldf(data, name_dataset, att_class ):\n",
    "    \"\"\"\n",
    "    Save filtered dataset into csv file \n",
    "    \"\"\"\n",
    "    from weka.core.converters import Saver\n",
    "\n",
    "    output = \"AfterFS/\" + name_dataset + \"_\" + att_class + \"_FS.csv\"\n",
    "\n",
    "    saver = Saver(classname=\"weka.core.converters.CSVSaver\")\n",
    "    saver.save_file(data, output)\n",
    "    print(\"Save dataset after Filter Selection as \" + str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26f97e60",
   "metadata": {
    "id": "pm-oJWGx1Kn8"
   },
   "outputs": [],
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdfcc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "script_location = sys.path[0]\n",
    "home = os.path.dirname(os.path.dirname(script_location))\n",
    "home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37c21b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(home, snakemake.input[\"ind\"]), header=None)\n",
    "metadata.columns = [\"Genome\", \"metadata\"]\n",
    "metadata = metadata.set_index(\"Genome\")\n",
    "metadata.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f2ca181",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = os.path.join(home, snakemake.input[\"out\"])\n",
    "inputdir2 = os.path.join(inputdir, \"Annotation_results\")\n",
    "os.chdir(inputdir2)\n",
    "!ls\n",
    "print(\"Current directory: \" + str(inputdir2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a57c97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_directory = os.path.join(inputdir2, \"AfterFS\")\n",
    "if \"AfterFS\" not in os.listdir():\n",
    "    os.makedirs(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86ed73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if \"Statistics\" not in file and \"metadata\" not in file and \"Orfs_per_genome\" not in file \\\n",
    "        and \"evolution\" not in file and \"FS\" not in file and \"Feature_selection\" not in file \\\n",
    "        and \"description\" not in file and \"after_SubsetEval\" not in file:\n",
    "        print(file)\n",
    "        name = file.split(\".\")[0]\n",
    "        print(name)\n",
    "        final = name + \"_metadata.csv\"\n",
    "        if final not in file:\n",
    "            df = pd.read_csv(file)\n",
    "            df = df.set_index(\"index\").T\n",
    "            df = pd.merge(df, metadata, how=\"left\", left_index=True, right_index=True)\n",
    "            df = df.rename_axis(\"genome\")\n",
    "            df.to_csv(name + \"_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22861d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for file in os.listdir():\n",
    "    if \"metadata\" in file and \"metadata_metadata\" not in file and \"Statistics\" not in file and \"Orfs_per_genome\" not in file and \"description\" not in file and \"after_SubsetEval\" not in file:\n",
    "        l.append(file)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8c3f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Home: \" + str(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "642e0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evolution = pd.read_csv(os.path.join(home, \"databases/Security_evolution.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b073878",
   "metadata": {
    "executionInfo": {
     "elapsed": 518653,
     "status": "aborted",
     "timestamp": 1613579489821,
     "user": {
      "displayName": "Sandra Godinho Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKiYpTpKSyb7YRzVp-sIJSQ7jzTN-pkrqCoLX0=s64",
      "userId": "18072981659281703353"
     },
     "user_tz": 0
    },
    "id": "NxCUHJ54UOkl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First round - Feature selection for Genus class\n",
    "i=0\n",
    "class_ = \"metadata\"\n",
    "\n",
    "for file in l:\n",
    "    print(\"==========================================================\")\n",
    "    print(\"====================== New dataset =======================\")\n",
    "    name_file = str(file).split(\".\")[0] + \"_\" + class_ + \"_FS.csv\" #future file name of the output\n",
    "    print(\"Dataset: \" + str(file) +\", Class: \" + str(class_) + \", i: \"+ str(i))\n",
    "    if file in os.listdir(): #check if file exists in folder\n",
    "        print(file)\n",
    "        data, name_dataset = LoadDataset(file, i)\n",
    "        data = FirstPreprocessing(data, i, class_)\n",
    "        data = SelectClass(data)\n",
    "        data = LoaderSubsetEval(data, i, name_dataset, class_) \n",
    "        d2, d3_f, optimal = SelectionOptimalParam(data, i, class_)\n",
    "        PlotOptimalParam(d2, class_)\n",
    "        PlotOptimalParamFMeasure(d3_f, class_)\n",
    "        data, evlTest, cls, pred_output = ImplementFeatureSelection(data, optimal, i)\n",
    "        SaveFinaldf(data, name_dataset, class_)\n",
    "        df_evolution.to_csv(os.path.join(inputdir, \"Feature_selection.csv\"), index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3671d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(inputdir, \"Feature_selection.csv\"))\n",
    "df = df.dropna(how='all')   \n",
    "df[\"Dataset\"] = df[\"Dataset\"].str.replace(\"_metadata\",\"\")\n",
    "#df = df.unstack(\"Dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a1f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
